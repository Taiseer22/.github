import torch
from diffusers import StableDiffusionPipeline
import argparse
import os

def generate_image(prompt, output_folder="outputs/images"):
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (ÙƒØ±Øª Ø§Ù„Ø´Ø§Ø´Ø© NVIDIA Ø£Ùˆ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¹Ø§Ø¯ÙŠ)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸš€ ÙŠØªÙ… Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…: {device}")

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Stable Diffusion v1.5)
    # Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ ÙÙŠ Ø£ÙˆÙ„ Ù…Ø±Ø© ÙÙ‚Ø· ÙˆÙŠÙØ®Ø²Ù† ÙÙŠ Ø¬Ù‡Ø§Ø²Ùƒ
    model_id = "runwayml/stable-diffusion-v1-5"
    
    print("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...")
    pipe = StableDiffusionPipeline.from_pretrained(
        model_id, 
        torch_dtype=torch.float16 if device == "cuda" else torch.float32
    )
    pipe = pipe.to(device)

    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©
    print(f"âœ¨ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ ÙˆØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ù„Ù€: {prompt}")
    image = pipe(prompt).images[0]

    # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³Ù… ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ (Ø£ÙˆÙ„ 10 ÙƒÙ„Ù…Ø§Øª)
    file_name = f"{prompt[:15].replace(' ', '_')}.png"
    save_path = os.path.join(output_folder, file_name)
    image.save(save_path)
    
    print(f"âœ… ØªÙ… Ø¨Ù†Ø¬Ø§Ø­! Ø§Ù„ØµÙˆØ±Ø© Ø¬Ø§Ù‡Ø²Ø© Ù‡Ù†Ø§: {save_path}")

if __name__ == "__main__":
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ù…Ù† Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø± (Terminal)
    parser = argparse.ArgumentParser(description="AI Image Generator")
    parser.add_argument("--prompt", type=str, required=True, help="Ø§Ù„ÙˆØµÙ Ø§Ù„Ù†ØµÙŠ Ù„Ù„ØµÙˆØ±Ø©")
    
    args = parser.parse_args()
    generate_image(args.prompt)
